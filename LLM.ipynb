{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6b19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Optional, Any, Dict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnableLambda\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525f5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/amrasov/Downloads/all_patents_v2.json', 'r') as file:  \n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4cc215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in data:\n",
    "    if 'Phenyl-sulfamates as aromatase inhibitors' in _['text']:\n",
    "        hui = _['text']\n",
    "        break\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_patent_text(text: str) -> str:\n",
    "\n",
    "    cleaned_text = re.sub(r'-\\n', '', text)\n",
    "    cleaned_text = re.sub(r'\\n{3,}', '\\n\\n', cleaned_text)\n",
    "    cleaned_text = re.sub(r' {2,}', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'^[ \\t]+|[ \\t]+$', '', cleaned_text, flags=re.MULTILINE)\n",
    "    return cleaned_text\n",
    "\n",
    "hui = clean_patent_text(hui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b030f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiologicalActivity(BaseModel):\n",
    "    activity_type: Optional[str] = Field(description=\"e.g., 'Ki', 'IC50'\")\n",
    "    value: Optional[float] = Field(description=\"The numerical value.\")\n",
    "    units: Optional[str] = Field(description=\"e.g., 'nM', 'µM'\")\n",
    "    target: Optional[str] = Field(description=\"Name of the protein target.\")\n",
    "    compound: Optional[str] = Field(description=\"Name of the compound.\")\n",
    "    target_sequence: Optional[str] = Field(default=None, description=\"Amino acid sequence, NOT accession number.\")\n",
    "    compound_smiles: Optional[str] = Field(default=None, description=\"SMILES string.\")\n",
    "\n",
    "class ActivityCollection(BaseModel):\n",
    "    activities: List[BiologicalActivity]\n",
    "\n",
    "class ValidationResult(BaseModel):\n",
    "    is_valid: bool = Field(description=\"True if the core fields are correct.\")\n",
    "    reason: str = Field(description=\"Brief explanation of the decision.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84b9e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _repair_and_reserialize_json_string(llm_output: str) -> str:\n",
    "\n",
    "    fallback_json_string = '{\"activities\": []}'\n",
    "\n",
    "    try:\n",
    "        if llm_output.startswith(\"```json\"):\n",
    "            llm_output = llm_output.split(\"```json\\n\", 1)[1].split(\"\\n```\")[0]\n",
    "        llm_output = llm_output.strip()\n",
    "    except (IndexError, AttributeError):\n",
    "        pass\n",
    "\n",
    "    if not llm_output:\n",
    "        return fallback_json_string\n",
    "\n",
    "    try:\n",
    "        data = json.loads(llm_output)\n",
    "        if isinstance(data, list):\n",
    "            fixed_data = {\"activities\": [item for item in data if isinstance(item, dict) and item]}\n",
    "        elif isinstance(data, dict) and isinstance(data.get(\"activities\"), list):\n",
    "            data[\"activities\"] = [item for item in data[\"activities\"] if isinstance(item, dict) and item]\n",
    "            fixed_data = data\n",
    "        else:\n",
    "            return fallback_json_string\n",
    "        return json.dumps(fixed_data)\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # недогенерированные JSON'ы идут сюда\n",
    "        print(f\"  [!] INFO: JSON is invalid, attempting to repair a partial list...\")\n",
    "        start_key = '\"activities\":'\n",
    "        start_pos_key = llm_output.find(start_key)\n",
    "        start_pos_list = llm_output.find('[', start_pos_key)\n",
    "\n",
    "        if start_pos_list == -1:\n",
    "            print(\"  [!] ERROR: Could not find the start of the activities list '['. Giving up.\")\n",
    "            return fallback_json_string\n",
    "\n",
    "        partial_list_str = llm_output[start_pos_list:]\n",
    "        last_good_bracket_pos = partial_list_str.rfind('}')\n",
    "        \n",
    "        while last_good_bracket_pos != -1:\n",
    "            potential_list_str = partial_list_str[:last_good_bracket_pos + 1]\n",
    "            test_json_str = potential_list_str + ']'\n",
    "            \n",
    "            try:\n",
    "                repaired_list = json.loads(test_json_str)\n",
    "                if isinstance(repaired_list, list):\n",
    "                    print(f\"  [+] SUCCESS: Repaired partial JSON, saved {len(repaired_list)} items.\")\n",
    "                    final_data = {\"activities\": repaired_list}\n",
    "                    return json.dumps(final_data)\n",
    "            except json.JSONDecodeError:\n",
    "                last_good_bracket_pos = partial_list_str.rfind('}', 0, last_good_bracket_pos)\n",
    "        \n",
    "        # если не спасли JSON\n",
    "        print(\"  [!] ERROR: Could not repair the partial JSON. Giving up.\", llm_output)\n",
    "        return fallback_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3417a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(llm: BaseChatModel):\n",
    "    # агент-сборщик\n",
    "    def run_preprocessor(text: str) -> List[str]:\n",
    "        print(\"--- 1. Running Preprocessor Agent ---\")\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=20000, chunk_overlap=500, length_function=len)\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        print(f\"Text split into {len(chunks)} chunks.\")\n",
    "        return chunks\n",
    "\n",
    "    # агент-фильтр\n",
    "    def run_filter(chunks: List[str]) -> List[str]:\n",
    "        print(\"\\n--- 2. Running Filter Agent ---\")\n",
    "        keywords = ['ic50', 'ec50', 'ki', 'kd', 'activity', 'inhibition', 'binding', 'nm', 'µm', 'micromolar']\n",
    "        relevant_chunks = [chunk for chunk in chunks if any(keyword in chunk.lower() for keyword in keywords)]\n",
    "        print(f\"Found {len(relevant_chunks)} potentially relevant chunks.\")\n",
    "        return relevant_chunks\n",
    "\n",
    "    # агент-экстрактор\n",
    "    extractor_parser = PydanticOutputParser(\n",
    "        pydantic_object=ActivityCollection,\n",
    "        retry_on_error=False,\n",
    "        llm=None\n",
    "    )\n",
    "\n",
    "    extractor_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a meticulous and highly specialized biochemist expert. Your mission is to parse pharmaceutical and biochemical patents to extract biological activity data with extreme precision. You must understand the scientific context to correctly identify the roles of molecules.\n",
    "    \n",
    "    ### Core Scientific Concepts for Extraction:\n",
    "    This section provides the fundamental knowledge you must use to interpret the text.\n",
    "    \n",
    "    **1. Defining `compound` vs. `target` - THE MOST IMPORTANT RULE:**\n",
    "    \n",
    "    *   **`compound` (The \"Key\"):** This is the substance being tested, usually a smaller molecule. It's the \"actor\" or \"drug\".\n",
    "        *   **Types:** Small organic molecules, peptides, drug candidates, natural products, tool compounds, fragments.\n",
    "        *   **Examples:** \"imatinib\", \"aspirin\", \"atorvastatin\", \"cyclosporine A\", \"benzonitrile derivative\", \"quinazoline analog\", \"peptide P-123\", \"Example 4b\", \"the compound of formula (I)\".\n",
    "    \n",
    "    *   **`target` (The \"Lock\"):** This is the biological entity that the `compound` interacts with. It's usually a large biomolecule.\n",
    "        *   **Types:** Proteins, enzymes, receptors, ion channels, antibodies, nucleic acids.\n",
    "        *   **Examples:** \"EGFR kinase\", \"ABL1\", \"p38 MAP kinase\", \"human GlyT1\", \"the 5-HT2A receptor\", \"voltage-gated sodium channel Nav1.7\", \"a monoclonal antibody against TNF-alpha\", \"human topoisomerase II\".\n",
    "    \n",
    "    *   **CRITICAL LOGIC & COMMON PATTERNS (Study these carefully):**\n",
    "        *   **\"Inhibition\":** \"Compound X inhibited **Enzyme Y** with a Ki of 50 nM.\"\n",
    "            *   `compound`: \"Compound X\"\n",
    "            *   `target`: \"Enzyme Y\"\n",
    "        *   **\"Binding\":** \"The binding affinity (Kd) of **ligand A** for the **B-Receptor** was 1.2 µM.\"\n",
    "            *   `compound`: \"ligand A\"\n",
    "            *   `target`: \"B-Receptor\"\n",
    "        *   **\"Antagonism/Agonism\":** \"Molecule Z acts as an antagonist at the **dopamine D2 receptor** (EC50 = 30 nM).\"\n",
    "            *   `compound`: \"Molecule Z\"\n",
    "            *   `target`: \"dopamine D2 receptor\"\n",
    "        *   **Antibody-Antigen Interaction:** \"The antibody, clone 3F4, bound to **human VEGF** with a Kd of 5 pM.\"\n",
    "            *   `compound`: \"human VEGF\" (The antigen, which is the smaller molecule *relative to the antibody's specific binding site*, is treated as the compound in this context).\n",
    "            *   `target`: \"antibody, clone 3F4\"\n",
    "        *   **Inverse Case (Antibody as the Drug):** \"The therapeutic antibody **Trastuzumab** targets the **HER2 receptor**.\"\n",
    "            *   `compound`: \"Trastuzumab\" (Here the antibody IS the drug/compound being tested).\n",
    "            *   `target`: \"HER2 receptor\"\n",
    "        *   **Your primary task is to identify the drug-like molecule (`compound`) and the biological system it affects (`target`).**\n",
    "    \n",
    "    **2. Handling Activity Values and Units:**\n",
    "    \n",
    "    *   You MUST extract a **specific numerical `value`**.\n",
    "    *   If the text says \"in the nanomolar range\", \"active\", or \"potent\" without a specific number, **you MUST IGNORE and DISCARD that data point.**\n",
    "    *   The `units` field MUST be a standard abbreviation (e.g., 'nM', 'µM', 'M', 'pM'). Do NOT invent units or use descriptive text. If the unit is \"micromolar\", normalize it to \"µM\".\n",
    "    \n",
    "    **3. Handling Compound Lists and Tables:**\n",
    "    \n",
    "    *   **Lists:** \"Compounds A, B, and C inhibited the target with IC50s of 10, 25, and 50 nM, respectively.\" You MUST create **three separate entries**.\n",
    "    *   **Tables:** Process each row of a table as a separate data point.\n",
    "    *   **Ranges:** \"IC50 values for the series ranged from 10-100 nM.\" **DISCARD** this, as it does not link a specific compound to a specific value.\n",
    "    \n",
    "    ### Final Output Rules:\n",
    "    *   **LINKED DATA ONLY**: All fields in an entry must come from the same sentence or a clear, unambiguous context (like a table row).\n",
    "    *   **SMILES/SEQUENCES**: Only extract literal `compound_smiles` strings or `target_sequence` amino acid chains. Do not guess or infer them.\n",
    "    *   **FORMAT**: Your entire response MUST be a single, valid JSON object. This object must have a single key, `activities`, which holds a list of the extracted data points. If no valid activities are found according to ALL the rules above, return an empty list: `{{\"activities\": []}}`.\n",
    "    \n",
    "    {format_instructions}\"\"\"),\n",
    "        (\"user\", \"Here is the text to analyze:\\n---\\n{text_chunk}\\n---\")\n",
    "    ]).partial(format_instructions=extractor_parser.get_format_instructions())\n",
    "\n",
    "    extractor_chain = (\n",
    "        extractor_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        | RunnableLambda(_repair_and_reserialize_json_string) # чиним JSON, если генерация прервалась\n",
    "        | extractor_parser # парсим в Pydantic\n",
    "    )\n",
    "\n",
    "    # агент-валидатор\n",
    "    validator_parser = PydanticOutputParser(\n",
    "        pydantic_object=ValidationResult,\n",
    "        retry_on_error=False,\n",
    "        llm=None\n",
    "    )\n",
    "    \n",
    "    validator_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a highly precise and critical Quality Assurance Specialist for biochemical data. Your task is to validate extracted data points against two criteria: 1) Accuracy based on the text, and 2) Informational Value.\n",
    "    \n",
    "    ### Validation Criteria:\n",
    "    \n",
    "    **1. Accuracy Check (Is it in the text?):**\n",
    "    *   Verify that the core fields (`compound`, `target`, `activity_type`, `value`, `units`) are fully and accurately supported by the original text.\n",
    "    *   Ensure the relationship between them is correct as stated in the text.\n",
    "    \n",
    "    **2. Informational Value Check (Is the data useful?):**\n",
    "    *   This is a critical quality control step. A data point is considered **LOW-VALUE and INVALID** if the `compound` identifier is a generic, patent-specific placeholder that cannot be used for external database lookups.\n",
    "    *   **Generic Placeholders Include:** \"Example 1\", \"Example 25a\", \"Compound 42\", \"the compound of Example 10\", \"Preparation 5\".\n",
    "    *   **The Rule:** If the `compound` field contains such a generic placeholder **AND** the `compound_smiles` field is empty or null, you **MUST** mark the data point as invalid.\n",
    "    *   **Example Scenario:**\n",
    "        *   **Input:** `{{\"compound\": \"Example 8\", \"value\": 18.0, \"compound_smiles\": null}}`\n",
    "        *   **Your Decision:** `{{\"is_valid\": false, \"reason\": \"Compound identifier is a generic placeholder ('Example 8') without an associated SMILES string.\"}}`\n",
    "    *   **Exception:** If a SMILES string **IS** present (`compound_smiles` is not null), the data point is considered VALID even if the `compound` name is generic, because the structure is known.\n",
    "    \n",
    "    ### Final Instructions:\n",
    "    *   Apply both checks. A data point must pass both to be `is_valid: true`.\n",
    "    *   Respond ONLY with a valid JSON object with two fields: \"is_valid\" (boolean) and \"reason\" (a brief explanation for your decision, especially for invalid points).\n",
    "    \n",
    "    {format_instructions}\"\"\"),\n",
    "        (\"user\", \"Original Text:\\n---\\n{text_chunk}\\n---\\nExtracted Data Point to Verify:\\n{extracted_data}\")\n",
    "    ]).partial(format_instructions=validator_parser.get_format_instructions())\n",
    "    \n",
    "    validator_chain = validator_prompt | llm | validator_parser\n",
    "    \n",
    "    # цикл экстракции-валидации\n",
    "    def run_extraction_validation_loop(chunks: List[str]) -> List[BiologicalActivity]:\n",
    "        validated_activities = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"\\n--- 3/4. Processing Chunk {i+1}/{len(chunks)} with Extractor & Validator ---\")\n",
    "            try:\n",
    "                extracted_collection = extractor_chain.invoke({\"text_chunk\": chunk})\n",
    "                \n",
    "                if not extracted_collection.activities:\n",
    "                    print(\"  Extractor found 0 potential data points.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"  Extractor found {len(extracted_collection.activities)} potential data points.\")\n",
    "                for activity in extracted_collection.activities:\n",
    "                    validation_result = validator_chain.invoke({\"text_chunk\": chunk, \"extracted_data\": activity.model_dump_json(indent=2)})\n",
    "                    if validation_result.is_valid:\n",
    "                        print(f\"  [+] VALIDATED: Activity for {activity.compound}\")\n",
    "                        validated_activities.append(activity)\n",
    "                    else:\n",
    "                        print(f\"  [-] INVALID: Activity for {activity.compound}. Reason: {validation_result.reason}\")\n",
    "            except Exception as e:\n",
    "                # Эта ошибка теперь будет возникать только в действительно исключительных случаях\n",
    "                print(f\"  [!] FATAL ERROR during processing chunk {i+1}: {e}\")\n",
    "        return validated_activities\n",
    "\n",
    "    # агент-аггрегатор\n",
    "    def run_aggregator(validated_results: List[BiologicalActivity]) -> List[Dict]:\n",
    "        print(\"\\n--- 5. Running Aggregator Agent ---\")\n",
    "        final_list = []\n",
    "        seen = set()\n",
    "        for activity in validated_results:\n",
    "            value_rounded = round(activity.value, 4) if activity.value is not None else None\n",
    "            units_norm = activity.units if activity.units else None\n",
    "            target_norm = activity.target if activity.target else None\n",
    "            deduplication_key = (activity.compound, target_norm, value_rounded, units_norm)\n",
    "            \n",
    "            if deduplication_key not in seen:\n",
    "                final_list.append(activity.model_dump())\n",
    "                seen.add(deduplication_key)\n",
    "                print(f\"  -> Added entry for {activity.compound}\")\n",
    "            else:\n",
    "                print(f\"  -> Skipped duplicate entry for {activity.compound}\")\n",
    "        return final_list\n",
    "\n",
    "    # полный пайплайн\n",
    "    pipeline = (\n",
    "        RunnableLambda(run_preprocessor)\n",
    "        | RunnableLambda(run_filter)\n",
    "        | RunnableLambda(run_extraction_validation_loop)\n",
    "        | RunnableLambda(run_aggregator)\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81f20307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀🚀🚀 Starting Patent Extraction Pipeline (with Mistral AI)... 🚀🚀🚀\n",
      "\n",
      "--- 1. Running Preprocessor Agent ---\n",
      "Text split into 13 chunks.\n",
      "\n",
      "--- 2. Running Filter Agent ---\n",
      "Found 13 potentially relevant chunks.\n",
      "\n",
      "--- 3/4. Processing Chunk 1/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. Based on the provided text, there is no specific biological activity data that meets the criteria outlined in the instructions. The text discusses various compounds and their potential uses as inhibitors of steroid sulphatase and aromatase, but it does not provide specific numerical values for activities such as IC50, Ki, or Kd with corresponding units. Therefore, the output should be an empty list.\n",
      "\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 2/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. Based on the provided text, there are no specific biological activity data points that meet the criteria outlined. The text discusses various aspects of compounds and their potential uses, but it does not provide specific numerical values for biological activities such as IC50, Ki, or Kd with corresponding units and targets. Therefore, the output is an empty list.\n",
      "\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 3/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. Based on the provided text, there is no biological activity data that meets the criteria specified. The text discusses various chemical structures and preferences for different components (X, Y, Z, R1, R2, etc.) of compounds, but it does not provide any specific biological activity data such as IC50, Ki, or Kd values with corresponding targets and compounds.\n",
      "\n",
      "Therefore, the output is:\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 4/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 5/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. Based on the provided text, there are no specific biological activity data points that meet the criteria for extraction. The text discusses various aspects of pharmaceutical administration, cell cycling, and potential therapeutic uses of compounds, but it does not provide specific numerical values for biological activities such as IC50, Ki, or Kd with corresponding units and clearly identified compounds and targets.\n",
      "\n",
      "Therefore, the output is:\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 6/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 7/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 8/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. The provided text primarily describes the synthesis of various compounds but does not include any biological activity data. Therefore, there are no valid data points to extract according to the rules provided.\n",
      "\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 9/13 with Extractor & Validator ---\n",
      "  [!] INFO: JSON is invalid, attempting to repair a partial list...\n",
      "  [!] ERROR: Could not repair the partial JSON. Giving up. The provided text does not contain any specific biological activity data that meets the criteria outlined in the instructions. There are no mentions of compounds inhibiting, binding to, acting as antagonists or agonists, or any other interactions with specific targets that include explicit numerical values and units.\n",
      "\n",
      "Therefore, the output is an empty list:\n",
      "```json\n",
      "{\"activities\": []}\n",
      "```\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 10/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 11/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 12/13 with Extractor & Validator ---\n",
      "  Extractor found 0 potential data points.\n",
      "\n",
      "--- 3/4. Processing Chunk 13/13 with Extractor & Validator ---\n",
      "  Extractor found 27 potential data points.\n",
      "  [-] INVALID: Activity for STX1023. Reason: Compound identifier is a generic placeholder ('STX1023') without an associated SMILES string.\n",
      "  [+] VALIDATED: Activity for Anastrozole\n",
      "  [+] VALIDATED: Activity for STX1022\n",
      "  [-] INVALID: Activity for STX1522. Reason: Compound identifier 'STX1522' is a generic placeholder without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1522. Reason: Compound identifier is a generic placeholder ('STX1522') without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1523. Reason: Compound identifier 'STX1523' is a generic placeholder without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1523. Reason: Compound identifier is a generic placeholder ('STX1523') without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1528. Reason: Compound identifier 'STX1528' is a generic placeholder without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1528. Reason: Compound identifier 'STX1528' is a generic placeholder without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1729. Reason: Compound identifier 'STX1729' is a generic placeholder without an associated SMILES string.\n",
      "  [-] INVALID: Activity for STX1729. Reason: Compound identifier is a generic placeholder ('STX1729') without an associated SMILES string.\n",
      "  [+] VALIDATED: Activity for STX1731\n",
      "  [!] FATAL ERROR during processing chunk 13: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"service_tier_capacity_exceeded\",\"param\":null,\"code\":\"3505\"}\n",
      "\n",
      "--- 5. Running Aggregator Agent ---\n",
      "  -> Added entry for Anastrozole\n",
      "  -> Added entry for STX1022\n",
      "  -> Added entry for STX1731\n",
      "\n",
      "======================================\n",
      "   ✅ FINAL EXTRACTION RESULT (JSON)\n",
      "======================================\n",
      "[\n",
      "  {\n",
      "    \"activity_type\": \"IC50\",\n",
      "    \"value\": 1.5,\n",
      "    \"units\": \"nM\",\n",
      "    \"target\": \"Aromatase\",\n",
      "    \"compound\": \"Anastrozole\",\n",
      "    \"target_sequence\": null,\n",
      "    \"compound_smiles\": null\n",
      "  },\n",
      "  {\n",
      "    \"activity_type\": \"IC50\",\n",
      "    \"value\": 1.0,\n",
      "    \"units\": \"nM\",\n",
      "    \"target\": \"Aromatase\",\n",
      "    \"compound\": \"STX1022\",\n",
      "    \"target_sequence\": null,\n",
      "    \"compound_smiles\": null\n",
      "  },\n",
      "  {\n",
      "    \"activity_type\": \"% Inhibition\",\n",
      "    \"value\": 99.5,\n",
      "    \"units\": \"%\",\n",
      "    \"target\": \"Aromatase\",\n",
      "    \"compound\": \"STX1731\",\n",
      "    \"target_sequence\": null,\n",
      "    \"compound_smiles\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "api_key = 'ByOSmaa6I15d940cXAlwKTN2c40I6rst'\n",
    "model_name = \"mistral-large-latest\" \n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    api_key=api_key,\n",
    "    model=model_name,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "patent_extraction_pipeline = build_pipeline(llm)\n",
    "\n",
    "print(\"🚀🚀🚀 Starting Patent Extraction Pipeline (with Mistral AI)... 🚀🚀🚀\\n\")\n",
    "final_json_output = patent_extraction_pipeline.invoke(hui)\n",
    "\n",
    "print(\"\\n======================================\")\n",
    "print(\"   ✅ FINAL EXTRACTION RESULT (JSON)\")\n",
    "print(\"======================================\")\n",
    "print(json.dumps(final_json_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277201aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
